{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "VGG——使用块的网络，更大更深的AlexNet"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l\n",
    "import os\n",
    "\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'\n",
    "\n",
    "\n",
    "# 定义块\n",
    "def vgg_block(num_convs,in_channels,out_channels):\n",
    "               # 卷积层个数、输入通道数、输出通道数\n",
    "    layers = []\n",
    "    # 使用一个循环来构建卷积层，每个卷积层都是使用3x3的卷积核和大小为1的padding来保持特征图的大小不变\n",
    "    for _ in range(num_convs):\n",
    "        layers.append(nn.Conv2d(in_channels,out_channels,kernel_size=3,padding=1))\n",
    "        layers.append(nn.ReLU())\n",
    "        in_channels = out_channels\n",
    "    # 添加一个2x2的最大池化层，它将特征图的空间尺寸减半。这有助于减少参数量和计算量，并提取更加重要的特征\n",
    "    layers.append(nn.MaxPool2d(kernel_size=2,stride=2))\n",
    "    return nn.Sequential(*layers)  # 返回一个包含所有卷积层和池化层的Sequential模型\n",
    "\n",
    "\n",
    "conv_arch = ((1,64),(1,128),(2,256),(2,512),(2,512)) # 第一个参数为几层卷积，第二个参数为输出通道数\n",
    "\n",
    "\n",
    "# VGG\n",
    "def vgg(conv_arch):\n",
    "    conv_blks = []\n",
    "    in_channels = 1\n",
    "    for (num_convs, out_channels) in conv_arch:\n",
    "        conv_blks.append(vgg_block(num_convs,in_channels,out_channels))\n",
    "        in_channels = out_channels\n",
    "\n",
    "    return nn.Sequential(*conv_blks, nn.Flatten(),\n",
    "                         nn.Linear(out_channels * 7 * 7, 4096),nn.ReLU(),\n",
    "                         nn.Dropout(0.5), nn.Linear(4096,4096),nn.ReLU(),\n",
    "                         nn.Dropout(0.5), nn.Linear(4096,10))\n",
    "\n",
    "\n",
    "net = vgg(conv_arch)\n",
    "\n",
    "# 观察每个层输出的形状\n",
    "X = torch.randn(size=(1,1,224,224))\n",
    "for blk in net:\n",
    "    X = blk(X)\n",
    "    print(blk.__class__.__name__,'output shape:\\t', X.shape)\n",
    "\n",
    "ratio = 4\n",
    "small_conv_arch = [(pair[0], pair[1]//ratio) for pair in conv_arch] # 所有输出通道除以4\n",
    "net = vgg(small_conv_arch)\n",
    "\n",
    "lr, num_epochs, batch_size = 0.05, 10, 128\n",
    "train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size,resize=224)\n",
    "d2l.train_ch6(net,train_iter,test_iter,num_epochs,lr,d2l.try_gpu())\n",
    "\n",
    "d2l.plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
