{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Kaggle实战房价预测"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "下载DataSet"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import hashlib\n",
    "import tarfile\n",
    "import zipfile\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l\n",
    "import os\n",
    "\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'\n",
    "DATA_HUB = dict()\n",
    "DATA_URL = 'http://d2l-data.s3-accelerate.amazonaws.com/'\n",
    "\n",
    "\n",
    "# 下载一个DATA_HUB中的文件，返回本地文件名\n",
    "def download(name, cache_dir=os.path.join('.', '01_data/02_DataSet_Kaggle_House')):\n",
    "    assert name in DATA_HUB, f\"{name} 不存在于 {DATA_HUB}.\"\n",
    "    url, sha1_hash = DATA_HUB[name]\n",
    "    os.makedirs(cache_dir, exist_ok=True)\n",
    "    fname = os.path.join(cache_dir, url.split('/')[-1])\n",
    "    if os.path.exists(fname):\n",
    "        sha1 = hashlib.sha1()\n",
    "        with open(fname, 'rb') as f:\n",
    "            while True:\n",
    "                data = f.read(1048576)\n",
    "                if not data:\n",
    "                    break\n",
    "                sha1.update(data)\n",
    "        if sha1.hexdigest() == sha1_hash:\n",
    "            return fname\n",
    "    print(f'正在从{url}下载{fname}...')\n",
    "    r = requests.get(url, stream=True, verify=True)\n",
    "    with open(fname, 'wb') as f:\n",
    "        f.write(r.content)\n",
    "    return fname\n",
    "\n",
    "\n",
    "# 从给定函数提取所有信息\n",
    "def extractall(data):\n",
    "    features = []\n",
    "    for row in data:\n",
    "        features.extend(row)  # 假设每一行的数据都是表示特征的列表或向量\n",
    "    return features\n",
    "\n",
    "\n",
    "# 下载并解压zip/tar文件\n",
    "def download_extract(name, folder=None):\n",
    "    fname = download(name)\n",
    "    base_dir = os.path.dirname(fname)\n",
    "    data_dir, ext = os.path.splitext(fname)\n",
    "    if ext == '.zip':\n",
    "        fp = zipfile.ZipFile(fname, 'r')\n",
    "    elif ext in ('.tar', '.gz'):\n",
    "        fp = tarfile.open(fname, 'r')\n",
    "    else:\n",
    "        assert False, '只有zip/tar文件可以被解压缩'\n",
    "    fp, extractall(base_dir)\n",
    "    return os.path.join(base_dir, folder) if folder else data_dir\n",
    "\n",
    "\n",
    "# 下载函数\n",
    "def download_all():\n",
    "    for name in DATA_HUB:\n",
    "        download(name)\n",
    "\n",
    "\n",
    "DATA_HUB['kaggle_house_train'] = (DATA_URL + 'kaggle_house_pred_train.csv', '585e9cc9370b9160e7921475fbcd7d31219ce')\n",
    "DATA_HUB['kaggle_house_test'] = (DATA_URL + 'kaggle_house_pred_test.csv', 'fal9780a7b011d9b009e8bff8e99922a8ee2eb90')\n",
    "train_data = pd.read_csv(download('kaggle_house_train'))\n",
    "test_data = pd.read_csv(download('kaggle_house_test'))\n",
    "print(train_data.shape)  # 1460个样本，80个te特征，1个标号label\n",
    "print(test_data.shape)  # 测试样本没有标号label"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "房价预测"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l\n",
    "import os\n",
    "\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'\n",
    "\n",
    "train_data = pd.read_csv('01_Data/02_DataSet_Kaggle_House/kaggle_house_pred_train.csv')\n",
    "test_data = pd.read_csv('01_Data/02_DataSet_Kaggle_House/kaggle_house_pred_test.csv')\n",
    "\n",
    "# 将训练数据和测试数据中除了第一列和最后一列之外的所有特征进行合并，并存储在名为all_features的变量中\n",
    "all_features = pd.concat((train_data.iloc[:, 1:-1], test_data.iloc[:, 1:]))\n",
    "\n",
    "# 从all_features中筛选出数值类型的特征，并将它们的索引存储在名为 numeric_features的变量中\n",
    "numeric_features = all_features.dtypes[all_features.dtypes != 'object'].index  # 当值的类型不是object的话，就是一个数值\n",
    "all_features[numeric_features] = all_features[numeric_features].apply(\n",
    "    lambda x: (x - x.mean()) / (x.std()))  # 对数值数据变为总体为均值为 0，方差为 1的分布的数据\n",
    "all_features[numeric_features] = all_features[numeric_features].fillna(0)  # 将缺失值用 0填充\n",
    "\n",
    "all_features = pd.get_dummies(all_features, dummy_na=True)\n",
    "all_features.shape\n",
    "\n",
    "n_train = train_data.shape[0]  # 样本个数\n",
    "train_features = torch.tensor(all_features[:n_train].values, dtype=torch.float32)\n",
    "test_features = torch.tensor(all_features[n_train:].values, dtype=torch.float32)\n",
    "# train_data的SalePrice列是label值\n",
    "train_labels = torch.tensor(train_data.SalePrice.values.reshape(-1, 1), dtype=torch.float32)\n",
    "\n",
    "loss = nn.MSELoss()\n",
    "\n",
    "in_features = train_features.shape[1]\n",
    "\n",
    "\n",
    "def get_net():\n",
    "    net = nn.Sequential(nn.Linear(in_features, 1))\n",
    "    return net\n",
    "\n",
    "\n",
    "# 计算对数均方根误差\n",
    "def log_rmse(net, features, labels):\n",
    "    clipped_preds = torch.clamp(net(features), 1, float('inf'))  # 把模型输出的值限制在1和inf之间，inf代表无穷大（infinity的缩写）\n",
    "    rmse = torch.sqrt(loss(torch.log(clipped_preds), torch.log(labels)))  # 预测做log，label做log，然后丢到MSE损失函数里\n",
    "    return rmse.item()\n",
    "\n",
    "\n",
    "# 训练函数（借助Adam优化器）\n",
    "def train(net, train_features, train_labels, test_features, test_labels,\n",
    "          num_epochs, learning_rate, weight_decay, batch_size):\n",
    "    train_ls, test_ls = [], []  # 初始化训练损失列表和验证损失列表\n",
    "    train_iter = d2l.load_array((train_features, train_labels), batch_size)  # 将训练数据分化为小批量，并使用DataLoader将其包装为可迭代对象\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate,weight_decay=weight_decay)  # 使用Adam优化器来更新模型参数\n",
    "    for epoch in range(num_epochs):\n",
    "        for X, y in train_iter:\n",
    "            optimizer.zero_grad()  # 优化器梯度归零\n",
    "            l = loss(net(X), y)\n",
    "            l.backward()  # 反向传播，计算梯度\n",
    "            optimizer.step()  # 使用优化器更新模型参数\n",
    "        train_ls.append(log_rmse(net, train_features, train_labels))  # 计算并保存当前轮次中训练集和验证集的损失\n",
    "        if test_labels is not None:\n",
    "            test_ls.append(log_rmse(net, test_features, test_labels))  # 计算并保存验证集的损失\n",
    "    return train_ls, test_ls  # 返回训练集和验证集的损失列表\n",
    "\n",
    "\n",
    "# k折交叉验证\n",
    "def get_k_fold_data(k, i, X, y):  # 给定 k折，给定第几折，返回相应的训练集、测试集\n",
    "    assert k > 1\n",
    "    fold_size = X.shape[0] // k  # 每一折的大小为样本数除以k\n",
    "    X_train, y_train = None, None\n",
    "    for j in range(k):\n",
    "        idx = slice(j * fold_size, (j + 1) * fold_size)\n",
    "        X_part, y_part = X[idx, :], y[idx]\n",
    "        if j == i:\n",
    "            X_valid, y_valid = X_part, y_part\n",
    "        elif X_train is None:\n",
    "            X_train, y_train = X_part, y_part\n",
    "        else:\n",
    "            X_train = torch.cat([X_train, X_part], 0)\n",
    "            y_train = torch.cat([y_train, y_part], 0)\n",
    "    return X_train, y_train, X_valid, y_valid\n",
    "\n",
    "\n",
    "# 求训练和验证误差的平均值\n",
    "def k_fold(k, X_train, y_train, num_epochs, learning_rate, weight_decay, batch_size):\n",
    "    train_l_sum, valid_l_sum = 0, 0\n",
    "    for i in range(k):\n",
    "        data = get_k_fold_data(k, i, X_train, y_train)\n",
    "        net = get_net()\n",
    "        train_ls, valid_ls = train(net, *data, num_epochs, learning_rate, weight_decay, batch_size)\n",
    "        train_l_sum += train_ls[-1]\n",
    "        valid_l_sum += valid_ls[-1]\n",
    "\n",
    "        if i == 0:\n",
    "            d2l.plot(list(range(1, num_epochs + 1)), [train_ls, valid_ls],\n",
    "                     xlabel='epoch', ylabel='rmse', xlim=[1, num_epochs],\n",
    "                     legend=['train', 'valid'], yscale='log')\n",
    "        print(f'fold{i + 1},train log rmse {float(train_ls[-1]):f},'f'valid log rmse {float(valid_ls[-1]):f}')\n",
    "    return train_l_sum / k, valid_l_sum / k\n",
    "\n",
    "\n",
    "k, num_epochs, lr, weight_decay, batch_size = 5, 100, 5, 0, 64\n",
    "train_l, valid_l = k_fold(k, train_features, train_labels, num_epochs, lr, weight_decay, batch_size)\n",
    "print(f'{k}-折验证：平均训练log rmse：{float(train_l):f},'f'平均验证log rmse：{float(valid_l):f}')\n",
    "\n",
    "d2l.plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def train_and_pred(train_features, test_feature, train_labels, test_data, num_epochs, lr, weight_decay, batch_size):\n",
    "    net = get_net()\n",
    "    train_ls, _ = train(net, train_features, train_labels, None, None, num_epochs, lr, weight_decay, batch_size)\n",
    "    d2l.plot(np.arange(1, num_epochs + 1), [train_ls], xlabel='epoch',\n",
    "             ylabel='log rmse', xlim=[1, num_epochs], yscale='log')\n",
    "    print(f'train log rmse {float(train_ls[-1]):f}')\n",
    "    preds = net(test_features).detach().numpy()\n",
    "    test_data['SalePrice'] = pd.Series(preds.reshape(1, -1)[0])\n",
    "    submission = pd.concat([test_data['Id'], test_data['SalePrice']], axis=1)\n",
    "    submission.to_csv('submission.cvs', index=False)\n",
    "\n",
    "train_and_pred(train_features, test_features, train_labels, test_data,\n",
    "               num_epochs, lr, weight_decay, batch_size)\n",
    "\n",
    "d2l.plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
