{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to 01_data/01_DataSet_FashionMNIST\\FashionMNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26421880/26421880 [00:36<00:00, 728049.33it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting 01_data/01_DataSet_FashionMNIST\\FashionMNIST\\raw\\train-images-idx3-ubyte.gz to 01_data/01_DataSet_FashionMNIST\\FashionMNIST\\raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to 01_data/01_DataSet_FashionMNIST\\FashionMNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29515/29515 [00:00<00:00, 104984.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting 01_data/01_DataSet_FashionMNIST\\FashionMNIST\\raw\\train-labels-idx1-ubyte.gz to 01_data/01_DataSet_FashionMNIST\\FashionMNIST\\raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to 01_data/01_DataSet_FashionMNIST\\FashionMNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4422102/4422102 [00:11<00:00, 392309.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting 01_data/01_DataSet_FashionMNIST\\FashionMNIST\\raw\\t10k-images-idx3-ubyte.gz to 01_data/01_DataSet_FashionMNIST\\FashionMNIST\\raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to 01_data/01_DataSet_FashionMNIST\\FashionMNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5148/5148 [00:00<00:00, 5147145.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting 01_data/01_DataSet_FashionMNIST\\FashionMNIST\\raw\\t10k-labels-idx1-ubyte.gz to 01_data/01_DataSet_FashionMNIST\\FashionMNIST\\raw\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils import data\n",
    "from torchvision import transforms\n",
    "from d2l import torch as d2l\n",
    "from IPython import display\n",
    "\n",
    "def get_dataloader_workers():\n",
    "    \"\"\"使用4个进程来读取的数据\"\"\"\n",
    "    return 0\n",
    "\n",
    "def load_data_fashion_mnist(batch_size, resize=None):\n",
    "    \"\"\"下载Fashion-MNIST数据集，然后将其加载到内存中\"\"\"\n",
    "    trans = [transforms.ToTensor()]\n",
    "    if resize:\n",
    "        trans.insert(0,transforms.Resize(resize)) # 如果有Resize参数传进来，就进行resize操作\n",
    "    trans = transforms.Compose(trans)\n",
    "    mnist_train = torchvision.datasets.FashionMNIST(root=\"01_data/01_DataSet_FashionMNIST\",train=True,transform=trans,download=True)\n",
    "    mnist_test = torchvision.datasets.FashionMNIST(root=\"01_data/01_DataSet_FashionMNIST\",train=False,transform=trans,download=True)\n",
    "    return (data.DataLoader(mnist_train, batch_size, shuffle=True, num_workers=get_dataloader_workers()),\n",
    "           data.DataLoader(mnist_train, batch_size, shuffle=True, num_workers=get_dataloader_workers()))\n",
    "\n",
    "\n",
    "batch_size = 256\n",
    "train_iter, test_iter = load_data_fashion_mnist(batch_size) # 返回训练集、测试集的迭代器\n",
    "\n",
    "num_inputs = 784\n",
    "num_outputs = 10\n",
    "w = torch.normal(0,0.01,size=(num_inputs,num_outputs),requires_grad=True)\n",
    "b = torch.zeros(num_outputs,requires_grad=True)\n",
    "\n",
    "def softmax(X):\n",
    "    X_exp = torch.exp(X) # 每个都进行指数运算\n",
    "    partition = X_exp.sum(1,keepdim=True)\n",
    "    return X_exp / partition # 这里应用了广播机制\n",
    "\n",
    "# 实现softmax回归模型\n",
    "def net(X):\n",
    "    return softmax(torch.matmul(X.reshape((-1,w.shape[0])),w)+b) # -1为默认的批量大小，表示有多少个图片，每个图片用一维的784列个元素表示\n",
    "\n",
    "def cross_entropy(y_hat, y):\n",
    "    return -torch.log(y_hat[range(len(y_hat)),y]) # y_hat[range(len(y_hat)),y]为把y的标号列表对应的值拿出来。传入的y要是最大概率的标号\n",
    "\n",
    "def accuracy(y_hat,y):\n",
    "    \"\"\"计算预测正确的数量\"\"\"\n",
    "    if len(y_hat.shape) > 1 and y_hat.shape[1] > 1: # y_hat.shape[1]>1表示不止一个类别，每个类别有各自的概率\n",
    "        y_hat = y_hat.argmax(axis=1) # y_hat.argmax(axis=1)为求行最大值的索引\n",
    "    cmp = y_hat.type(y.dtype) == y # 先判断逻辑运算符==，再赋值给cmp，cmp为布尔类型的数据\n",
    "    return float(cmp.type(y.dtype).sum()) # 获得y.dtype的类型作为传入参数，将cmp的类型转为y的类型（int型），然后再求和\n",
    "\n",
    "# 可以评估在任意模型net的准确率\n",
    "def evaluate_accuracy(net,data_iter):\n",
    "    \"\"\"计算在指定数据集上模型的精度\"\"\"\n",
    "    if isinstance(net,torch.nn.Module): # 如果net模型是torch.nn.Module实现的神经网络的话，将它变成评估模式\n",
    "        net.eval()  # 将模型设置为评估模式\n",
    "    metric = Accumulator(2) # 正确预测数、预测总数，metric为累加器的实例化对象，里面存了两个数\n",
    "    for X, y in data_iter:\n",
    "        metric.add(accuracy(net(X),y),y.numel()) # net(X)将X输入模型，获得预测值。y.numel()为样本总数\n",
    "    return metric[0] / metric[1] # 分类正确的样本数 / 总样本数\n",
    "\n",
    "# Accumulator实例中创建了2个变量，用于分别存储正确预测的数量和预测的总数量\n",
    "class Accumulator:\n",
    "    \"\"\"在n个变量上累加\"\"\"\n",
    "    def __init__(self,n):\n",
    "        self.data = [0,0] * n\n",
    "\n",
    "    def add(self, *args):\n",
    "        self.data = [a+float(b) for a,b in zip(self.data,args)] # zip函数把两个列表第一个位置元素打包、第二个位置元素打包....\n",
    "\n",
    "    def reset(self):\n",
    "        self.data = [0.0] * len(self.data)\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        return self.data[idx]\n",
    "\n",
    "# 训练函数\n",
    "def train_epoch_ch3(net, train_iter, loss, updater):\n",
    "    if isinstance(net, torch.nn.Module):\n",
    "        net.train() # 开启训练模式\n",
    "    metric = Accumulator(3)\n",
    "    for X, y in train_iter:\n",
    "        y_hat = net(X)\n",
    "        l = loss(y_hat,y) # 计算损失\n",
    "        if isinstance(updater, torch.optim.Optimizer): # 如果updater是pytorch的优化器的话\n",
    "            updater.zero_grad()\n",
    "            l.mean().backward()  # 这里对loss取了平均值出来\n",
    "            updater.step()\n",
    "            metric.add(float(l)*len(y),accuracy(y_hat,y),y.size().numel()) # 总的训练损失、样本正确数、样本总数\n",
    "        else:\n",
    "            l.sum().backward()\n",
    "            updater(X.shape[0])\n",
    "            metric.add(float(l.sum()),accuracy(y_hat,y),y.numel())\n",
    "    return metric[0] / metric[2], metric[1] / metric[2] # 所有loss累加除以样本总数，总的正确个数除以样本总数\n",
    "\n",
    "\n",
    "\n",
    "class Animator:\n",
    "    def __init__(self, xlabel=None, ylabel=None, legend=None, xlim=None,\n",
    "                ylim=None, xscale='linear',yscale='linear',\n",
    "                fmts=('-','m--','g-.','r:'),nrows=1,ncols=1,\n",
    "                figsize=(3.5,2.5)):\n",
    "        if legend is None:\n",
    "            legend = []\n",
    "        d2l.use_svg_display()\n",
    "        self.fig, self.axes = d2l.plt.subplots(nrows,ncols,figsize=figsize)\n",
    "        if nrows * ncols == 1:\n",
    "            self.axes = [self.axes,]\n",
    "        self.config_axes = lambda: d2l.set_axes(self.axes[0],xlabel,ylabel,xlim,ylim,xscale,yscale,legend)\n",
    "        self.X, self.Y, self.fmts = None, None, fmts\n",
    "\n",
    "    def add(self, x, y):\n",
    "        if not hasattr(y, \"__len__\"):\n",
    "            y = [y]\n",
    "        n = len(y)\n",
    "        if not hasattr(x, \"__len__\"):\n",
    "            x = [x] * n\n",
    "        if not self.X:\n",
    "            self.X = [[] for _ in range(n)]\n",
    "        if not self.Y:\n",
    "            self.Y = [[] for _ in range(n)]\n",
    "        for i, (a,b) in enumerate(zip(x,y)):\n",
    "            if a is not None and b is not None:\n",
    "                self.X[i].append(a)\n",
    "                self.Y[i].append(b)\n",
    "        self.axes[0].cla()\n",
    "        for x, y, fmt in zip(self.X, self.Y, self.fmts):\n",
    "            self.axes[0].plot(x, y, fmt)\n",
    "        self.config_axes()\n",
    "        display.display(self.fig)\n",
    "        display.clear_output(wait=True)\n",
    "\n",
    "# 总训练函数\n",
    "def train_ch3(net,train_iter,test_iter,loss,num_epochs,updater):\n",
    "    animator = Animator(xlabel='epoch',xlim=[1,num_epochs],ylim=[0.3,0.9],\n",
    "                       legend=['train loss','train acc','test acc'])\n",
    "    for epoch in range(num_epochs):  # 变量num_epochs遍数据\n",
    "        train_metrics = train_epoch_ch3(net,train_iter,loss,updater) # 返回两个值，一个总损失、一个总正确率\n",
    "        test_acc = evaluate_accuracy(net, test_iter) # 测试数据集上评估精度，仅返回一个值，总正确率\n",
    "        animator.add(epoch+1,train_metrics+(test_acc,)) # train_metrics+(test_acc,) 仅将两个值的正确率相加，\n",
    "    train_loss, train_acc = train_metrics\n",
    "\n",
    "# 小批量随即梯度下降来优化模型的损失函数\n",
    "lr = 0.1\n",
    "def updater(batch_size):\n",
    "    return d2l.sgd([w,b],lr,batch_size)\n",
    "\n",
    "num_epochs = 10\n",
    "train_ch3(net,train_iter,test_iter,cross_entropy,num_epochs,updater)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
